# OH 7

- 2 datasets
- hard and soft clustering
- dimensionality reduction
- one of own choosing can be supervised or unsupervised (use labels or not)
- step 4 and 5 is one dataset and comparing to NN from P1
- steps
- clustering and analysis
- DR and analysis
- DR then clustering and analysis (compare and see if anything changed)
- DR on dataset, use for NN and compare to set without DR
    - if we are throwing away some features, are they affecting a model like NN?
- Clustering on same dataset as step 4 then NN (not Clustering AND DR)
    - for generated clustering features, can either replace features or add them to existing list of features
    - replacement of DR in part 4
- UL, so assuming there are not labels when learning the model
- in reference to the 4th DR algo being supervised or unsupervised
- cannot use labels to determine how many clusters are needed, but can be used when evaluating the clusters
    - can use labels for evaluation, but don't need to, a lot fot he time the number of clusters doesn't match number of classes
- LDA uses class labels, have the option to used that as 4th DR if you want
- you do need to look at eigenvalues ECA and kertosis(?) for ICA
- talk about how you determined the number of clusters for K means and EM, cannot be supervised (from class labels)
- then validate the number of clusters, using labels, vizualization, some unsupervized metric
- compare k means and EM, one is soft clustering one is hard clustering, what are advantages/disadvantages you see
- dimensionality reduction
- talk about what the algorithms are doing
- PCA - eigenvalues, maximum variance in the data
- ICA - tries to find independent components, kertotsis, randomized projection etc.
- if you can see any meaning in those reduced values
- DR + clustering
- cluster similar to part 1 and compare to part 1
- if something is different, as is usually the case, take specific cases and visualize them/provide intuition for what happened
- large number of combinations, don't need to look into all the differences, but pick a couple of examples
- DR + NN
- advantages and disadvantages of DR and how it affect perf of NN
- when you throw away info, makes things faster and hopefully get rid of some noise, but you are throwing away information
- how is it affecting performance in terms of time and convergence, as well as "value" of perf metric
- Cluster + NN
- same as part 4
- compare with normal NN and part 4
- can use clustering output as only features (like DR) or can add them as additional ones (not throwing away info, adding filtered versions)
- using cluster output as only features
    - really simple features
    - can negatively affect performance
- probably want some kind of visualization to understand what the new projection looks like
  - can use another algo like TSNE or pair-wise plots for specific features
- same with clustering, same kinds of visuals if you like, or just include metrics about how dense and separated the clusters are
- eigenvalues for PCA
- kertosis for ICA
- randomized projection would use reconstruction error
- 4th - use whatever makes sense


# OH 8

- describing clusters
  - TSNE
  - could also use a feature plot of features and normalized values going to clusters
    - each row is one feature and the x axis is the value to see how points are spread with different clusters
  - just some way to visualize it to give some intuition
- DR is projecting the data into a new space, try to visualize that space and see if it makes sense connecting it to the data
  - PCA maximizes variance along axes, we know what they mean, could plot the first few and see if they connect in any way to the dataset
  - ICA tries to find independent components in the data, see if there is anything about those independent components that connects with the data
- using clustering for the features in NN
  - would have k clusters, could one hot encode the clusters as features
  - could also add them to the existing features or whatever else you want to do
  - take the cluster centers and add the closest one to each data point as a new feature or a vector of distances to each center
  - need to understand how they will contribute, if it is just DR, then it is clear, it is reducing the number of features
    - if they are added as additional features, what is it adding to the performance of the NN
- selecting number of components for RCA/ICA
  - may not elbow in the graph, may need to define some threshold and justify it
  - from assignment kurtosis for ICA and reconstruction error for RCA
    - reconstruction error should be calculated by the error between the original and reconstructed data, use the pseudo inverse of the projection matrix
  - not every DR method suits every dataset
- you can use prediction datasets, but you don't know the targets
  - cannot use labels to determine optimal number of clusters
  - have to approach it as an unsupervised problem
  - check connection to dataset, this can be done via the actual labels
  - optimal number of clusters may not match the labels
    - looks at features in a certain way that may not line up with the labels
- cannot use labels to find optimal k or number of dimensions, but can use them for validation
- can, but don't *have* to, look at labels, can look at cohesiveness and separation of clusters
- can not focus about visualization if the dataset is too complicated, or can use domain knowledge to visualize a subset of important features with something like pair plots and coloring based on cluster labels
  - can also use TSNE
  - should validate your clusters
  - might be aided by something like a silhouette score
- number of components for ICA
  - simple way is to choose solutions that are more kurtotic
  - choose the solution that is better then look into that solution and choose the dimensions that give the most nonguassian, for instance
    - can pretty much use anything for the first step, simple way is to use average kurtosis, then choose the most kutotic solution
- for PCA, include some kind of eigenvalue analysis and some kind of kurtosis analysis for ICA
- average kurtosis is just average of the kurtosis across each component, which you can calculate the kurtosis of each
- it is important to normalize when there is distance involved, so it is recommended here
- be sure to split into training and test, since a NN is still run at the end
  - for clustering and DR, don't really need to worry about the test set, could be used for validation though
- Choosing k for clustering
  - can use elbow method or silhouette score (be careful as it does not penalize complexity, so best score is points-1), sum of squared distances
  - something that gives a plot, then choose best based on lowest error or elbow method, etc.
- TSNE can mislead you, it is basically just a tool to help visualize your data in a smaller number of dimensions, would need to do research about what it is doing and how it may mislead you
  - Don't really need to visualize it in fewer dimensions, just need to be able to connect it to the dataset
- determining if ICA is capturing something meaningful
  - can visualize the data after ICA using a pair plot or TSNE or something similar
  - and/or can look at how features are contributing to the components generated
  - no objective answer, just exploration depending on the dataset
- dont need to do cross validation, but need to validate the clustering
  - can use the training data and use some metric, e.g., sum of squared distances, to get k, then use some other metric and see if it agrees with the k found
- don't need to dig deep for which cutoff threshold is going to give the best result, there are already enough experiments to run, just use one
- validation for DR
  - not a set per se, but look at the components selected and see how they link back to the original data
- ICA
  - choose solution with highest average kurtosis, then look at that solution and find the components with highest kurtosis
- TSNE plot throws away information about features
  - mainly use it to see spread of points in cluster, separation, etc.
- can retune NN in background, don't need to report LC/MCC
- reconstruction error
  - something like
  ```python
transformed_data = (...).fit_transform(X)
inverse_data = np.linalg.pinv((...).components_.T)
reconstructed_data = transformed_data.dot(inverse_data)
  ```
  - use MSE as error metric
- LDA is a better choice in terms of multiclass, but can be used on binary in theory, just may not be good
- can iterate over a large number of k's to narrow down optimal range for target number of clusters
  - e.g., 2 to 100, and if you see a good elbow between 2 and 20, you can narrow the search
  - also necessary to define what "best" is for the comparison
- not necessary to run a simple classifier after DR, it is just another dimension to verify the results
  - should do at least one of the discussed items to verify
  - basic requirements: eigenvalues, kurtosis, reconstruction error

## OH 9

- designed to compare DR methods, so it can be good to structure report in such a way as to make them clumped to make it easier to compare
- kurtosis is vulernable to noise and outliers in the data
  - make sure to plot components where you are getting a higher kurtosis to find more non-gaussian ones
- make sure ICA kurtosis is done on ICA components, not reconstructed values
- lda makes number of features less than number of classes, which can lead to an aggressive reduction
- clustering as DR is simplistic, that is fine
  - using the clusters as the features, either just cluster or one hot encoded, so 1 for the cluster it is in, 0 else
- convergence criteria is student defined
  - generally, performance is not changing, it has the value it is going to have
  - cannot improve, or cannot significantly, without a much larger number of iterations
- it is ok to not spend a long time on kmeans if it doesn't make sense and it is better to use a variation, like with gower distance, just explain why it doesn't make sense and why this other one does that you will be using
- plots for DR can be hard, since you are not working with the original data, it's projected into new dimensions
  - we really care about the new features and what they mean
  - plot the best 2-3 dimensions and see if there is anything else that pops out
    - pca will have the highest variance, but is there anything else that you see
    - many not be trivial
  - just try to provide some intuition about the new dimensions
- NN
  - need performance and convergence behavior
  - don't need the learning curve, but could be used to show convergence
- linear decline for reconstruction error is fine, it just means that each defines the same amount of your data
  - especially for RCA
  - should be doing some tuning for rca to make sure it is the best version of projection
- all DR methods are not expected to work well
  - depends on assumptions of algo and how data conforms
- look at all pair plots for experimenting, but only interesting ones are needed in the report
- ideally the NN should be tuned for each method, but it is not penalized if you don't
  - if you have time
  - if you are not throwing away a lot of information
  - mainly for architecture of the network, like height and width, but others should still be tuned per
- elbow method and silhouette score may not agree on k, that is fine
  - silhouette is better defined though, so it may be the one to trust
  - silhouette will give best score for clusters == points, so avoid that trap
- need to provide results for all dr -> cluster combos, but not visualizations
  - should be able to give optimal number of clusters and difference to part 1
- for clustering
  - find best k
  - validate clusters with some score supervised or not
  - trying to understand how the clusters look
- it is possible to have more or fewer cluster than features
- AIC and BIC make more sense for EM than silhouette wince they work better for probabilistic
- kurtosis is the measure of non-gaussian-ity
  - law of large numbers, when you add a bunch of signals together they will become a gaussian, so maximize non-gaussian-ness
- only the absolute value of the kurtosis matter
- kurtosis over the components, not the transformed data